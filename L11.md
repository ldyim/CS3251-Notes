# L11


## TCP 3 way handshake
- needed because 2 way does not work
  - if packets get resent, then the server will think that the client is trying to connect again or that the client is connected when it isn't


## Closing a TCP connection
- client, server each close their side of connection
  - send TCP segment with FIN bit = 1
- respond to received FIN with ACK
  - on receiving FIN, ACK can be combined with own FIN
- simultaneous FIN exchanges can be handled 
  - - from github copilot 
    - if both sides send FIN at same time, then both sides will receive ACKs
    - if both sides receive ACKs, then both sides will send FINs
    - if both sides send FINs, then both sides will receive ACKs 
  
## Principles of congestion control
- too many senders sending too fast
- congestion:
  - informally: "too many sources sending too much data too fast for network to handle"
  - manifestations:
    - long delays (queueing in router buffers)
    - packet loss (buffer overflow at routers)
  - different from flow control!
    - one sender too fast for one receiver 
  - congestion control is a top 10 problem 

## Scenario 2
- one router, finite buffers
- sender retransmits lost, timed-out packets
  - application-layer input = application output lambda in = lambda out
- transport layer input includes retransmissions: lambda prime in >= lambda in
- idealization: perfect knowledge
  - sender sends only when router buffer is not full


- Idealization: some perfect knowledge
  - packets can be lost (dropped at router) due to full buffers
  - sender knows when packet has been dropped: only resends if packet known to be lost

## realistic scenario: un-needed duplicates
- packets can be lost, dropped at router due to full buffers - requiring retransmissions 
- but sender times can time out prematurely sending two copies, both of which are delivered to receiver

- cost of congestion:
  - more work for given receiver throughput 
  - unneeded retranmissions: link carries  multiple copies of a packet
    -  decreasing maximum achievable throughput
 -  when packet dropped, any unstream transmission capacity and buffering used for that packet was wasted 
- congestion control asks people to back off


## insights
- throughput can never exceed capacity of bottleneck link
- delay increases as capacity approached
- loss/retransmission decreases effective throughput
- un-needed duplicates further decrease effective throughput
- upstream transmission capacity/ buffering wasted for packets lost downstream


## approaches towards congestion control
- end-end congestion control:
  - no explicit feedback from network
  - congestion inferred from observed loss, delay 
- network-assisted congestion control:
  - router provide direct feedback to sending/receiving hosts with flows passing through congested router
  - may indicate congestion level or explicitly set sending rate
  - TCP ECN, ATM, DECbit protocol


## TCP congestion control: AIMD
- approach: senders can increase sending rate until packet loss occurs, then decrease sending rate on loss event
- additive increase 
  - increase sending rate by 1 maximum segment size every RTT until loss detected
- multiplicative decrease
  - decrease sending rate by half when loss detected

- multiplicative decrease detail: sending rate is 
  - cut in half on loss detected by triple duplicate ACK
  - cut to 1 MSS (maximun segment size) when loss detected by timeout 
- why AIMD?
  - AIMD-  a distributed, asynchronous, self-organizing algorithm
    - optimize congested flow rates network wide!
    - have desirable stability properties 
- TCP sender limits transmission: lastbytesent - lastbyteacked <= cwnd
- cwnd is dynamically adjusted in response to observed network congestion (implementing TCP congestion control)
- TCP sending behavior oughly: send cwnd bytes, wait RTT for ACKS, then send more bytes

## TCP slow start
- when connection begins, increase rate exponentially until first loss event:
- initially cwnd = 1 MSS
- double cwnd every RTT until loss detected
- done by incrementing cwnd for each ACK received by 1 
- summary: initial rate is slow, but ramps up exponentially until loss detected